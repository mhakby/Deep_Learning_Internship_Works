{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e40728-afae-4b84-9207-9d75663cd105",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T20:16:41.130465Z",
     "start_time": "2024-09-17T20:16:36.742842Z"
    }
   },
   "outputs": [],
   "source": [
    "# Jupyter Notebook -- Dataset Preprocessing: Starting The Process of Cleaning and Organizing The Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcfadda-7666-4021-9736-a29f6c517b6a",
   "metadata": {},
   "source": [
    "* Pandas for reading, processing, editing, analyzing and manipulating data,\n",
    "* Numpy for numerical calculations,\n",
    "* Train_test_split from the scikit-learn library to divide the dataset into training and test sets,\n",
    "* StandardScaler was used to scale and standardize the data. (The mean of the numerical data in the features is considered as 0 and the standard deviation is 1, and all numerical data is standardized for model training.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c34001c-f1c4-42ee-beba-26bfef84d810",
   "metadata": {},
   "source": [
    "1) First, the data set is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde271c9-4715-47fb-9482-8304831a85f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data.csv')\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cbfc55-e5a9-4a87-839f-9d48a042806c",
   "metadata": {},
   "source": [
    "* With `inplace=True`, we removed rows containing NaN values from the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f56298-263d-4fba-b12d-dfd3c6cc903d",
   "metadata": {},
   "source": [
    "2) Features are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd745bbe-4dd1-4a3b-87a6-0bee774a1eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[['Word_Count', 'Link_Count', 'Image_Count', 'Video_Count', 'Has_Ads', 'Domain_Age', 'Payment_Present',\n",
    "                 'Login_Present', 'User_Comments', 'Cookies_Present', 'H1_Counts', 'H2_Counts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa7e2e6a-cbe8-4264-a9c9-c5824da2232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data['Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba1469-6f79-4745-98a6-526b6fc40d39",
   "metadata": {},
   "source": [
    "3) Control of class numbers. This control is an error-proofing position that I use for the weak dataset I use. Normally, this may not be necessary in a well-prepared dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d7b2cf3-50af-4053-a44b-6aa5843df804",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_per_class = 2\n",
    "class_counts = target.value_counts()\n",
    "valid_classes = class_counts[class_counts >= min_samples_per_class].index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6ab6c4-7ea1-4997-aae3-04a2a2704da8",
   "metadata": {},
   "source": [
    "Comparison of category tags and tags created with valid_classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2b2e099-59c0-4d6f-af66-0edb6788bfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = data[data['Category'].isin(valid_classes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9306b53-0cbe-49ed-87e4-129c2b4bea5b",
   "metadata": {},
   "source": [
    "Selecting only the rows in valid indexes and assigning them as the new target value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fc20893-216c-408b-a14b-1db1643dc5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.loc[filtered_data.index]\n",
    "target = filtered_data['Category']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2c1269-4f36-4706-9c24-07e405d66cb2",
   "metadata": {},
   "source": [
    "4) Preparing training, test and validation data sets with `train_test_split()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8255126-eb87-4e1a-bed0-94d5c713507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(features, target, test_size=0.3, random_state=42, stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81041bb-0787-4147-bfb6-dbad82f59052",
   "metadata": {},
   "source": [
    "* We separate the database to train(%70) and temp(%30)(will be separated to test(%15) and validation(%15) at the following codes.)\n",
    "* With `stratify=target`, class distributions are preserved when dividing the data set. For example, if there is an imbalance between classes (e.g. 70% class A, 30% class B), these ratios are preserved in both training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b40de6-1e62-4dc2-98e5-a017b813bc84",
   "metadata": {},
   "source": [
    "Removing classes that do not have enough examples in the temporary dataset (X_temp, y_temp) after the first split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a66b68d-f61a-42ad-a673-169a79070cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_class_counts = y_temp.value_counts()\n",
    "valid_temp_classes = temp_class_counts[temp_class_counts >= min_samples_per_class].index\n",
    "\n",
    "# Remove classes that do not have enough examples from the temporary dataset\n",
    "X_temp = X_temp[y_temp.isin(valid_temp_classes)]\n",
    "y_temp = y_temp[y_temp.isin(valid_temp_classes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241af367-e38d-4fc0-8159-aae8ac3bf0d1",
   "metadata": {},
   "source": [
    "In the data set that we consider as Train and Temp, the data allocated for Temp is divided separately for validation and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "947f849a-f0d4-4555-982d-c791644ccd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb615e8-7bab-451d-b039-d0f126835888",
   "metadata": {},
   "source": [
    "Scaling of feature values for each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cddebdb7-e751-4b19-b878-dc113ca8319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e0d5e0-d46e-4e9f-8469-5b0a2b4179bf",
   "metadata": {},
   "source": [
    "Saving the prepared data sets locally as a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64763bc0-3cca-4c62-895e-4f088ba12851",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ac94017-5623-41d3-8409-ba051ef763dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(current_directory, 'X_train_scaled.npy'), X_train_scaled)\n",
    "np.save(os.path.join(current_directory, 'y_train.npy'), y_train)\n",
    "np.save(os.path.join(current_directory, 'X_val_scaled.npy'), X_val_scaled)\n",
    "np.save(os.path.join(current_directory, 'y_val.npy'), y_val)\n",
    "np.save(os.path.join(current_directory, 'X_test_scaled.npy'), X_test_scaled)\n",
    "np.save(os.path.join(current_directory, 'y_test.npy'), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a919169-261d-4048-9df2-80f6f34a40d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing completed and saved.\n"
     ]
    }
   ],
   "source": [
    "print(\"Data processing completed and saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
